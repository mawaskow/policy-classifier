{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will scrape policies from the gov.ie website.\n",
    "\n",
    "In your command line, ``cd`` into this repository.\n",
    "\n",
    "``cd`` into the ``policy_scraping`` task directory, then ``cd`` again into the ``policy_scraping`` scrapy environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd() # should be base directory of repository\n",
    "os.chdir(cwd+\"/policy_scraping/policy_scraping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run ``scrapy crawl goviefor -O ../outputs/goviefor.json`` (or you can change the -O argument to whatever you would prefer the output file information to be).\n",
    "\n",
    "This command will generate a json containing the metadata about all the policies as well as download all files to the same outputs directory under ``forestry/full``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!! scrapy crawl goviefor -O ../outputs/goviefor.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will consolidate the metadata and text of the policy PDFs into one dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cwd) # back to base directory\n",
    "import json\n",
    "from populate_corpora.pdfs_to_jsons import scrp_itm_to_fulltxt\n",
    "FILE_DIR= cwd+\"/policy_scraping/policy_scraping/outputs\" # or whatever output directory you gave the scraper for its output json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cwd+\"/policy_scraping/outputs/goviefor.json\",\"r\", encoding=\"utf-8\") as f:\n",
    "    metad = json.load(f)\n",
    "pdf_dict = scrp_itm_to_fulltxt(metad, FILE_DIR+\"/forestry/full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have your own collection of pdfs to process and don't have a metadata file, you can use this next function on just the file directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from populate_corpora.pdfs_to_jsons import pdfs_to_txt_dct\n",
    "pdf_dict = pdfs_to_txt_dct(FILE_DIR+\"/forestry/full\") # or whatever your policy directory is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this project, we only want the texts of the PDFs in cleaned sentences anyways. So we'll go ahead and extract/clean those sentences, then load them into the dictionary format that doccano (labeling platform) uses. Finally, if we want, we can use a simple keyword search to prelabel some of the sentences with a \"incentive class mention\" label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from populate_corpora.data_cleaning import get_clean_text_sents, format_sents_for_doccano, prelabeling\n",
    "EN_TOKENIZER = nltk.data.load(\"tokenizers/punkt/english.pickle\") # need tokenizer for our text cleaning\n",
    "clean_sents= get_clean_text_sents(pdf_dict, EN_TOKENIZER)\n",
    "doccano_dict = format_sents_for_doccano(clean_sents)\n",
    "prelab_doccano_dict = prelabeling(doccano_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can download this dictionary as a json to import into our doccano instance for labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cwd+\"/populate_corpora/outputs/ready_to_label.json\", 'w', encoding=\"utf-8\") as outfile:\n",
    "    json.dump(prelab_doccano_dict, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Labeling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a doccano instance for our labeling, but we also had to do some data validation with an external annotator. This section generates a subset for a labeler from the hand-labeled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from populate_corpora.annotators import label_dct, resample_dict\n",
    "from populate_corpora.data_cleaning import dcno_to_sentlab\n",
    "with open(cwd+\"/inputs/19Jan25_firstdatarev.json\",\"r\", encoding=\"utf-8\") as f: #our hand-labeled dataset\n",
    "    dcno_json = json.load(f)\n",
    "\n",
    "sents_d, labels_d = dcno_to_sentlab(dcno_json)\n",
    "label_lib = label_dct({\"text\":sents_d[i], \"label\":[labels_d[i]]} for i in range(len(sents_d)))\n",
    "resampled = resample_dict(label_lib)\n",
    "ann_frame = [{'text':sent, 'label':[]} for key in resampled.keys() for sent in resampled[key]]\n",
    "\n",
    "with open(cwd+\"/inputs/subsample_to_label.json\", 'w', encoding=\"utf-8\") as outfile:\n",
    "    json.dump(ann_frame, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the inter-annotator agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cwd+\"/inputs/annotation_odon.json\",\"r\", encoding=\"utf-8\") as f: #our hand-labeled dataset\n",
    "    ann_json = json.load(f)\n",
    "\n",
    "sents_a, labels_a = dcno_to_sentlab(ann_json)\n",
    "# correct labels\n",
    "swap_labs = {'non-incentive':'Non-Incentive', 'fine':'Fine', 'tax deduction':'Tax_deduction', 'credit':'Credit', 'direct payment':'Direct_payment', 'supplies':'Supplies', 'technical assistance':'Technical_assistance'}\n",
    "sents_a2, labels_a2 = [], []\n",
    "for i, lab in enumerate(labels_a):\n",
    "  try:\n",
    "    labels_a2.append(swap_labs[lab])\n",
    "    sents_a2.append(sents_a[i])\n",
    "  except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 0.7707100591715976 for 62 entries\n",
      "Binary: 0.7114788004136505 for 62 entries\n",
      "Multiclass: 0.9534883720930233 for 26 entries\n"
     ]
    }
   ],
   "source": [
    "from populate_corpora.annotators import get_common_sentlabs, all_to_bin, all_to_sharedmc\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "s_sents, labels_sc, labels_sa = get_common_sentlabs(sents_d, labels_d, sents_a2, labels_a2)\n",
    "print(f\"All: {cohen_kappa_score(labels_sc, labels_sa)} for {len(labels_sc)} entries\")\n",
    "\n",
    "labs_binc, labs_bina = all_to_bin(labels_sc), all_to_bin(labels_sa)\n",
    "print(f\"Binary: {cohen_kappa_score(labs_binc, labs_bina)} for {len(labs_binc)} entries\")\n",
    "\n",
    "mclabsc, mclaba = all_to_sharedmc(labels_sc, labels_sa, labs_binc, labs_bina)\n",
    "print(f\"Multiclass: {cohen_kappa_score(mclabsc, mclaba)} for {len(mclabsc)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to make a new human-in-the-loop dataset using by doing sentence similarity searches with predefined queries. We have five queries for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cwd+\"/populate_corpora/outputs/ready_to_label.json\",\"r\", encoding=\"utf-8\") as f:\n",
    "    prelab_doccano_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prelab_doccano_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpopulate_corpora\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_cleaning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dcno_to_only_sents\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# loading all sentences, not just the labeled ones\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# or reload cwd+\"/populate_corpora/outputs/ready_to_label.json\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m all_sents \u001b[38;5;241m=\u001b[39m dcno_to_only_sents(\u001b[43mprelab_doccano_dict\u001b[49m) \n\u001b[0;32m      7\u001b[0m embs, s_sentences, model \u001b[38;5;241m=\u001b[39m run_embedder(sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dev\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mall_sents, unique\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# uses our queries dictionary, but obvs you can make your own\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prelab_doccano_dict' is not defined"
     ]
    }
   ],
   "source": [
    "from populate_corpora.query_augment import run_embedder, run_queries, QUERIES_DCT\n",
    "from populate_corpora.data_cleaning import dcno_to_only_sents\n",
    "\n",
    "# loading all sentences, not just the labeled ones\n",
    "# or reload cwd+\"/populate_corpora/outputs/ready_to_label.json\"\n",
    "all_sents = dcno_to_only_sents(prelab_doccano_dict) \n",
    "embs, s_sentences, model = run_embedder(sample=False, dev='cuda', data=all_sents, unique=True)\n",
    "# uses our queries dictionary, but obvs you can make your own\n",
    "qry_dct = run_queries(embs, s_sentences, model, qry_dct=QUERIES_DCT, dev='cuda', sim_thresh=0.5, res_lim=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll parse the results and create a dataset of sentences labeled by the query process, but we first need to filter them to only include sentences found by at least 4/5 queries for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from populate_corpora.query_augment import consolidate_sents, crossref_sents\n",
    "lbl_qry_dct = consolidate_sents(qry_dct, QUERIES_DCT)\n",
    "filt_qry_dct = crossref_sents(lbl_qry_dct, 4)\n",
    "qry_rs_dataset = [{'text': sent, 'label': lbl} for lbl in list(filt_qry_dct) for sent in filt_qry_dct[lbl]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cwd+\"/populate_corpora/outputs/augmented_to_label.json\", 'w', encoding=\"utf-8\") as outfile:\n",
    "    json.dump(qry_rs_dataset, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fine-Tuning the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
