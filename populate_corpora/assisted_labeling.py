'''
Built off of old repo's /tasks/data_augmentation/assisted_labelling.py

Enable consolidation from all the different pdf jsons (as will need to be generated by json_cleaning.py)-- for when we do labeling that way

Change queries dct
'''

import json
import os
from os import listdir
from os.path import isfile, join
import random
import time
import csv
import sys
import argparse
from tqdm import tqdm
import textwrap

# Model libraries
from sentence_transformers import SentenceTransformer
import sentencepiece
from scipy.spatial import distance
import numpy as np

from json import JSONEncoder

class NumpyArrayEncoder(JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return JSONEncoder.default(self, obj)
    
QUERIES_DCT = {
    "Otorgamiento de estímulos crediticios por parte de el estado" : "Credit",
"Estos créditos podrían beneficiar a sistemas productivos asociados a la pequeña y mediana producción" : "Credit",
"Se asocia con créditos de enlace del Banco del Estado" : "Credit", 
"Acceso al programa de garantía crediticia para la actividad económica" : "Credit",
"El banco establecerá líneas de crédito para que el sistema financiero apoye la pequeña, mediana y microempresa" : "Credit",
"Dentro de los incentivos económicos se podrá crear un bono para retribuir a los propietarios por los bienes y servicios generados." : "Direct_payment",
"Acceso a los fondos forestales para el pago de actividad" : "Direct_payment",
"Se bonificará el 90% de los costos de repoblación para las primeras 15 hectáreas y de un 75% respecto las restantes" : "Direct_payment",
"El estado dará un incentivo que se pagará una sola vez a los propietarios forestales" : "Direct_payment",
"Incentivos en dinero para cubrir los costos directos e indirectos del establecimiento y manejo de areas de producción" : "Direct_payment",
"Toda persona física o moral que cause daños estará obligada a repararlo o compensarlo" : "Fine",
"Disminuir los riesgos para el inversionista implementando mecanismos de aseguramiento" : "Guarantee",
"Podrá garantizarse el cumplimiento de la actividad mediante fianza otorgada a favor del estado por cualquiera de las afianzadoras legalmente autorizadas." : "Guarantee",
"El sujeto de derecho podrá recibir insumos para la instalación y operación de infraestructuras para la actividad económica." : "Supplies",
"Se facilitará el soporte técnico a  través de la utilización de guías, manuales, protocolos, paquetes tecnológicos, procedimientos, entre otros." : "Supplies",
"Se concederán incentivos en especie para fomentar la actividad en forma de insumos" : "Supplies",
"Se otorgarán incentivos fiscales para la actividad primaria y también la actividad de transformación" : "Tax_deduction",
"De acuerdo con los lineamientos aprobados se concederá un 25% de descuento en el pago del derecho de aprovechamiento" : "Tax_deduction",
"Las bonificaciones percibidas o devengadas se considerarán como ingresos diferidos en el pasivo circulante y no se incluirán para el cálculo de la tasa adicional ni constituirán renta para ningún efecto legal hasta el momento en que se efectúe la explotación o venta" : "Tax_deduction",
"Los contratistas que suscriban contratos de exploración y/o explotación, quedan exentos de cualquier impuesto sobre los dividendos, participaciones y utilidades" : "Tax_deduction",
"Exención de los derechos e impuestos, incluyendo el Impuesto a la Transferencia de Bienes Muebles y a la Prestación de Servicios, en la importación de sus bienes, equipos y accesorios, maquinaria, vehículos, aeronaves o embarcaciones" : "Tax_deduction",
"Se facilitará formación Permanente Además del acompañamiento técnico, los sujetos de derecho participarán en un proceso permanente de formación a lo largo de todo el año, que les permita enriquecer sus habilidades y capacidades " : "Technical_assistance",
"Contribuir en la promoción para la gestión, a través de la capacitación, asesoramiento, asistencia técnica y educación de los usuarios" : "Technical_assistance",
"Asesoría prestada al usuario por un operador acreditado, conducente a elaborar, acompañar y apoyar la adecuada ejecución técnica en terreno de aquellas prácticas comprometidas en el Plan de Manejo" : "Technical_assistance",
"Para la ejecución de programas de capacitación, adiestramiento y otorgamiento de becas para la preparación de personal , así como para el desarrollo de tecnología en actividades directamente relacionadas con las operaciones objeto del contrato" : "Technical_assistance",
"Apoyo técnico y en formulación de proyectos y conexión con mercados" : "Technical_assistance"}

def create_sentence_embeddings(model, sentences):
    embeddings = []
    for sentence in sentences:
        embeddings.append(model.encode(sentence.lower(), show_progress_bar=False))
    return embeddings
    
def sentence_similarity_search(model, queries, embeddings, sentences, similarity_limit, results_limit, cuda, prog_bar):
    results = {}
    for query in tqdm(queries):
        Ti = time.perf_counter()
        similarities = get_distance(model, embeddings, sentences, query, similarity_limit, cuda, prog_bar)
        results[query] = similarities[0:results_limit] #results[transformer][query] = similarities[0:results_limit]
        Tf = time.perf_counter()
        print(f"Similarity search for query '{query}' has been done in {Tf - Ti:0.2f}s.")
    return results

# This function helps debugging misspelling in the values of the dictionary
def check_dictionary_values(dictionary):
    check_country = {}
    check_incentive = {}
    for key, value in dictionary.items():
        incentive, country = value.split("-")
        check_incentive[incentive] = 0
        check_country[country] = 0
    print(check_incentive)
    print(check_country)

def get_distance(model, embeddings, sentences, query, similarity_treshold, cuda, prog_bar):
    if cuda:
        query_embedding = model.encode(query.lower(), show_progress_bar=prog_bar, device='cuda')
    else:
        query_embedding = model.encode(query.lower(), show_progress_bar=prog_bar)
    highlights = []
    for i in range(len(sentences)):
        try:
            sentence_embedding = embeddings[i]
            score = 1 - distance.cosine(sentence_embedding, query_embedding)
            if score > similarity_treshold:
                highlights.append([i, score, sentences[i]])
        except KeyError as err:
            print(sentences[i])
            print(embeddings[i])
            print(err)
    highlights = sorted(highlights, key = lambda x : x[1], reverse = True)
    return highlights

# To show the contents of the results dict, particularly, the length of the first element and its contents
def show_results(results_dictionary):
    i = 0
    for key1 in results_dictionary:
        for key2 in results_dictionary[key1]:
            if i == 0:
                print(len(results_dictionary[key1][key2]))
                print(results_dictionary[key1][key2])
            i += 1

############################################################################

def sentence_dissimilarity_search(model, queries, embeddings, sentences, dissimilarity_limit, results_limit, cuda, prog_bar):
    results = {}
    for query in tqdm(queries):
        Ti = time.perf_counter()
        similarities = get_r_distance(model, embeddings, sentences, query, dissimilarity_limit, cuda, prog_bar)
        results[query] = similarities[0:results_limit] #results[transformer][query] = similarities[0:results_limit]
        Tf = time.perf_counter()
        print(f"Similarity search for query '{query}' has been done in {Tf - Ti:0.2f}s.")
    return results

def get_r_distance(model, embeddings, sentences, query, dissimilarity_treshold, cuda, prog_bar):
    if cuda:
        query_embedding = model.encode(query.lower(), show_progress_bar=prog_bar, device='cuda')
    else:
        query_embedding = model.encode(query.lower(), show_progress_bar=prog_bar)
    highlights = []
    for i in range(len(sentences)):
        try:
            sentence_embedding = embeddings[i]
            score = 1 - distance.cosine(sentence_embedding, query_embedding)
            if score < dissimilarity_treshold:
                highlights.append([i, score, sentences[i]])
        except KeyError as err:
            print(sentences[i])
            print(embeddings[i])
            print(err)
    highlights = sorted(highlights, key = lambda x : x[1], reverse = True)
    return highlights

############################################################################

def run_embedder(sample=True, cuda=False, data=[]):
    script_info = "Running "
    if sample:
        script_info += "sample"
    else:
        script_info += "all sentences"
    if cuda:
        script_info += " on GPU."
    else:
        script_info += " on CPU."
    print(script_info)

    sentences = data

    if sample:
        #random.seed(9)
        sentences = random.sample(sentences, 10)

    Ti = time.perf_counter()

    transformer_name = 'xlm-r-bert-base-nli-stsb-mean-tokens'

    if cuda:
        model = SentenceTransformer(transformer_name, device="cuda")
    else:
        model = SentenceTransformer(transformer_name)
    
    print("Loaded model. Now creating sentence embeddings.")

    embs = create_sentence_embeddings(model, sentences)

    Tf = time.perf_counter()

    print(f"The building of a sentence embedding database in the current models has taken {Tf - Ti:0.2f}s.")

    return embs, sentences, model

def run_queries(embs, sentences, model, cuda=False, sim_thresh=0.2, res_lim=1000):
    prog_bar = False
    print("Now running queries.")

    queries = []
    for query in QUERIES_DCT:
        queries.append(query)

    #check_dictionary_values(queries_dict)

    results_dict = sentence_similarity_search(model, queries, embs, sentences, sim_thresh, res_lim, cuda, prog_bar)

    return results_dict

def run_binary(embs, sentences, model, cuda=False, output_path=".",sim_thresh=0.2, res_lim=1000):
    prog_bar = False
    print("Now running queries.")

    queries = []
    for query in QUERIES_DCT:
        queries.append(query)

    #check_dictionary_values(queries_dict)

    results_dct = sentence_dissimilarity_search(model, queries, embs, sentences, sim_thresh, res_lim, cuda, prog_bar)

    return results_dct

def convert_pretagged(pre_lab):
    '''
    Takes pre_tagged dct generated in assisted_labelling.py
    resolves the queries and keys
    '''
    qdct = QUERIES_DCT.copy()
    for query in list(qdct):
        raw_label = qdct[query]
        label = raw_label.split("-")[0]
        label = label.replace("_", " ")
        qdct[query] = label
    new_dct = {}
    for qry in tqdm(list(pre_lab)):
        label = qdct[qry]
        for sent_unit in pre_lab[qry]:
            # the format has the sentence as the last element in the sublist
            sentence = sent_unit[-1]
            new_dct[sentence] = label
    return new_dct

def pre_tag_parse(pretag):
    '''
    Preps dct for training
    '''
    sentences = []
    labels = []
    for query in list(pretag):
        for result in pretag[query]:
            sentences.append(result[2])
            labels.append(QUERIES_DCT[query])
    return sentences, labels

def pre_tag_parse_bin(pretag):
    '''
    Preps dct for training
    '''
    sentences = []
    for query in list(pretag):
        for result in pretag[query]:
            sentences.append(result[2])
    return sentences

def main():
    st = time.time()
    sample = False
    cuda = True
    input_path = "C:/Users/Allie/Documents/GitHub/policy-classifier/populate_corpora/outputs/full_text_sents.json"
    output_path = "C:/Users/Allie/Documents/GitHub/policy-classifier/populate_corpora/outputs/"
    if sample:
        sim_thresh = 0.2
    else:
        sim_thresh = 0.5
    ##############
    with open(input_path,"r", encoding="utf-8") as f:
        sentences = json.load(f)
    embs, s_sentences, model = run_embedder(sample, cuda, sentences)
    
    pret_dct = run_queries(embs, s_sentences, model, cuda, sim_thresh=0.5, res_lim=1000)
    sentences, labels = pre_tag_parse(pret_dct)

    bin_dct = run_binary(embs, s_sentences, model, cuda, 0.2, res_lim=1000)
    neg_sents = pre_tag_parse_bin(bin_dct)

    with open(os.path.join(output_path, 'pret_dct.json'), 'w', encoding="utf-8") as outfile:
        json.dump(bin_dct, outfile, ensure_ascii=False, indent=4)
    with open(os.path.join(output_path, 'pret_sents.json'), 'w', encoding="utf-8") as outfile:
        json.dump(sentences, outfile, ensure_ascii=False, indent=4)
    with open(os.path.join(output_path, 'pret_labels.json'), 'w', encoding="utf-8") as outfile:
        json.dump(labels, outfile, ensure_ascii=False, indent=4)
    with open(os.path.join(output_path, 'neg_bin_sents.json'), 'w', encoding="utf-8") as outfile:
        json.dump(neg_sents, outfile, ensure_ascii=False, indent=4)

    ##############
    et = time.time()-st
    print("Time elapsed total:", et//60, "min and", round(et%60), "sec")
    '''
    input_path= "C:\\Users\\allie\\Documents\\GitHub\\policy-data-analyzer\\tasks\\data_augmentation\\output\\EXP1\\Pre_tagged_0.75.json"
    output_path= "C:\\Users\\allie\\Documents\\GitHub\\policy-data-analyzer\\tasks\\data_augmentation\\output\\EXP1\\Pre_tagged_0.75_fixed.json"
    convert_pretagged(input_path, output_path)
    '''

if __name__ == '__main__':
    main()
    '''
    
    # cmd line arg
    # python assisted_labeling.py -l 'spanish' -s -i "C:/Users/Ales/Documents/GitHub/policy-data-analyzer/tasks/text_preprocessing/output/new/" -o "C:/Users/Ales/Documents/GitHub/policy-data-analyzer/tasks/data_augmentation/output/sample/"

    parser = argparse.ArgumentParser()

    parser.add_argument('-l', '--lang', required=True,
                        help="Language for sentence preprocessing/splitting. Current options are: 'spanish'")
    parser.add_argument('-s', '--sample', required=False, default=False, action='store_true',
                        help="Run sample of sentences instead of all sentences")
    parser.add_argument('-c', '--cuda', required=False, default=False, action='store_true',
                        help="Use cuda to run (if cuda-enabled GPU)")
    parser.add_argument('-i', '--input_path', required=True,
                        help="Input path for sentence split jsons.")
    parser.add_argument('-o', '--output_path', required=True,
                        help="Output path for result jsons.")
    parser.add_argument('-t', '--thresh', required=False, default=0.2,
                        help="Similarity threshold for sentences.")
    parser.add_argument('-r', '--lim', required=False, default=1000,
                        help="Results limit for sentence search.")

    args = parser.parse_args()

    main(args.lang, args.sample, args.cuda, args.input_path, args.output_path, float(args.thresh), int(args.lim))
    '''