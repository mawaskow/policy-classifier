{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "#!pip install huggingface_hub\n",
    "#!pip install ipywidgets\n",
    "#!pip install accelerate bitsandbytes\n",
    "#!pip install -U transformers \n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\", quantization_config=quantization_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PTH= \"C:/Users/Allie/Documents/GitHub/policy-classifier/policy_scraping/outputs/scraped_pdfs.json\"\n",
    "\n",
    "with open(INPUT_PTH,\"r\", encoding=\"utf-8\") as f:\n",
    "    pdf_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OutOfMemoryError: CUDA out of memory. Tried to allocate 16.36 GiB. \n",
    "#GPU 0 has a total capacty of 16.00 GiB of which 0 bytes is free. \n",
    "#Of the allocated memory 24.31 GiB is allocated by PyTorch, \n",
    "#and 1.56 GiB is reserved by PyTorch but unallocated. \n",
    "#If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  \n",
    "#See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
    "\n",
    "indexs = tokenizer(\"X Yes No\", return_tensors=\"pt\")\n",
    "\n",
    "yes_idx = indexs[\"input_ids\"][0,2]\n",
    "no_idx = indexs[\"input_ids\"][0,3]\n",
    "\n",
    "for hash in tqdm(pdf_json):\n",
    "  try:\n",
    "    inputs = tokenizer(f\"\"\"{pdf_json[hash][\"text\"]}\n",
    "    ---\n",
    "    Is this policy about restoring the environment? Answer Yes or No:\n",
    "  \"\"\", return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens=5, min_new_tokens=1, output_scores=True, return_dict_in_generate=True)\n",
    "    text = tokenizer.batch_decode(outputs[\"sequences\"])[0]\n",
    "    print(text)\n",
    "    print(outputs[\"scores\"][0][0,yes_idx])\n",
    "    print(outputs[\"scores\"][0][0,no_idx])\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    print(f\"Could not process {pdf_json[hash]['doc_title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"\"\"Saccharomyces cerevisiae has been used for at least eight millennia in the production of alcoholic beverages (41). Along with ethanol and carbon dioxide, fermenting cultures of this yeast produce many low-molecular-weight flavor compounds. These alcohols, aldehydes, organic acids, esters, organic sulfides, and carbonyl compounds have a strong impact on product quality. Indeed, the subtle aroma balance of these compounds in fermented foods and beverages is often used as an organoleptic fingerprint for specific products and brands (42). Food fermentation by yeast and lactic acid bacteria is accompanied by the formation of the aliphatic and aromatic alcohols known as fusel alcohols. Fusel oil, which derives its name from the German word fusel (bad liquor), is obtained during the distillation of spirits and is enriched with these higher alcohols. While fusel alcohols at high concentrations impart off-flavors, low concentrations of these compounds and their esters make an essential contribution to the flavors and aromas of fermented foods and beverages. Fusel alcohols are derived from amino acid catabolism via a pathway that was first proposed a century ago by Ehrlich (13). Amino acids represent the major source of the assimilable nitrogen in wort and grape must, and these amino acids are taken up by yeast in a sequential manner (23, 32). Amino acids that are assimilated by the Ehrlich pathway (valine, leucine, isoleucine, methionine, and phenylalanine) are taken up slowly throughout the fermentation time (32). After the initial transamination reaction (Fig. ​(Fig.1),1), the resulting α-keto acid cannot be redirected into central carbon metabolism. Before α-keto acids are excreted into the growth medium, yeast cells convert them into fusel alcohols or acids via the Ehrlich pathway. FIG. 1. The Ehrlich pathway. Catabolism of branched-chain amino acids (leucine, valine, and isoleucine), aromatic amino acids (phenylalanine, tyrosine, and trytophan), and the sulfur-containing amino acid (methionine) leads to the formation of fusel acids and ... Current scientific interest in the Ehrlich pathway is supported by increased demands for natural flavor compounds such as isoamyl alcohol and 2-phenylethanol, which can be produced from amino acids in yeast-based bioconversion processes (14), as well as by the need to control flavor profiles of fermented food products. The goal of this paper is to present a concise centenary overview of the biochemistry, molecular biology, and physiology of this important pathway in S.\"\"\",\n",
    "\"\"\"Sense induction seeks to automatically identify word senses\n",
    "directly from a corpus. A key assumption underlying previous work is that the context\n",
    "surrounding an ambiguous word is indicative of its meaning. Sense induction is thus\n",
    "typically viewed as an unsupervised clustering problem where the aim is to partition a\n",
    " word's contexts into different classes, each representing a word sense. Our work places\n",
    "  sense induction in a Bayesian context by modeling the contexts of the ambiguous word as\n",
    "  samples from a multinomial distribution over senses which are in turn characterized\n",
    "  as distributions over words. The Bayesian framework provides a principled way\n",
    "  to incorporate a wide range of features beyond lexical co-occurrences and to\n",
    "  systematically assess their utility on the sense induction task. The proposed\n",
    "  approach yields improvements over state-of-the-art systems on a benchmark dataset\"\"\"]\n",
    "\n",
    "indexs = tokenizer(\"X Yes No\", return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "yes_idx = indexs[\"input_ids\"][0,2]\n",
    "no_idx = indexs[\"input_ids\"][0,3]\n",
    "\n",
    "for text in texts:\n",
    "  inputs = tokenizer(f\"\"\"{text}\n",
    "  ---\n",
    "  Is this article about inducing the number of senses a word would have in a dictionary? Answer Yes or No:\n",
    "\"\"\", return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "  outputs = model.generate(**inputs, max_new_tokens=5, min_new_tokens=1, output_scores=True, return_dict_in_generate=True)\n",
    "  text = tokenizer.batch_decode(outputs[\"sequences\"])[0]\n",
    "  print(text)\n",
    "  print(outputs[\"scores\"][0][0,yes_idx])\n",
    "  print(outputs[\"scores\"][0][0,no_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
